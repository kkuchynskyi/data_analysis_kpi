{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      "Wine type               178 non-null int64\n",
      "Alcohol                 178 non-null float64\n",
      "Malic acid              178 non-null float64\n",
      "Ash                     178 non-null float64\n",
      "Alcalinity of ash       178 non-null float64\n",
      "Magnesium               178 non-null int64\n",
      "Total phenols           178 non-null float64\n",
      "Flavanoids              178 non-null float64\n",
      "Nonflavanoid phenols    178 non-null float64\n",
      "Proanthocyanins         178 non-null float64\n",
      "Color intensity         178 non-null float64\n",
      "Hue                     178 non-null float64\n",
      "OD280                   178 non-null float64\n",
      "Proline                 178 non-null int64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "names = [\"Wine type\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \"Total phenols\", \"Flavanoids\", \n",
    "         \"Nonflavanoid phenols\", \"Proanthocyanins\", \"Color intensity\", \"Hue\", \"OD280\", \"Proline\"]\n",
    "df = pd.read_csv(\"./wine.data\", index_col=False, names=names)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13) (133, 3)\n",
      "(45, 13) (45, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kirill\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# normalization, train-test split and one hot encoding\n",
    "for column in names[1:]:\n",
    "    df[column] = (df[column] - df[column].mean())/df[column].std()\n",
    "Y = df.iloc[:, 0].values.reshape(-1, 1)\n",
    "Y = OneHotEncoder().fit_transform(Y).toarray()\n",
    "X = df.iloc[:, 1:].values\n",
    "num_samples = X.shape[0]\n",
    "train_samples = int(0.75*num_samples)\n",
    "indexes = np.arange(num_samples)\n",
    "random.shuffle(indexes)\n",
    "X, Y = X[indexes], Y[indexes]\n",
    "X_train, Y_train = X[:train_samples, :], Y[:train_samples]\n",
    "X_test, Y_test = X[train_samples:, :], Y[train_samples:]\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fc_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,091\n",
      "Trainable params: 1,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "inputs = keras.Input(shape=(13,))\n",
    "x = keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = keras.layers.Dense(3, activation=\"softmax\")(x)\n",
    "fc_model = keras.Model(inputs=inputs, outputs=outputs, name=\"fc_model\")\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.9266 - accuracy: 0.7547 - val_loss: 0.8558 - val_accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.7847 - accuracy: 0.9340 - val_loss: 0.7631 - val_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.9717 - val_loss: 0.7087 - val_accuracy: 0.9259\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.9717 - val_loss: 0.6722 - val_accuracy: 0.9259\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.9717 - val_loss: 0.6493 - val_accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.9811 - val_loss: 0.6362 - val_accuracy: 0.9630\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.9630\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 0.9630\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.9630\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1880ed3cd88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# training\n",
    "fc_model.fit(X_train, Y_train, batch_size=4, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.6072 - accuracy: 0.9333\n",
      "Test loss: 0.6072059869766235\n",
      "Test accuracy: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "test_scores = fc_model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                432650    \n",
      "=================================================================\n",
      "Total params: 433,546\n",
      "Trainable params: 433,418\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(64, 3, activation=\"relu\")(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(10)(x)\n",
    "cnn_model = keras.Model(inputs=inputs, outputs=outputs, name=\"cnn_model\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - 90s 479ms/step - loss: 1.4247 - accuracy: 0.8134 - val_loss: 0.6994 - val_accuracy: 0.8388\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 78s 413ms/step - loss: 0.4926 - accuracy: 0.8875 - val_loss: 0.6473 - val_accuracy: 0.8612\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 75s 399ms/step - loss: 0.3279 - accuracy: 0.9145 - val_loss: 0.5655 - val_accuracy: 0.8751\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 76s 407ms/step - loss: 0.2326 - accuracy: 0.9325 - val_loss: 0.5564 - val_accuracy: 0.8841\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 76s 405ms/step - loss: 0.1759 - accuracy: 0.9453 - val_loss: 0.6256 - val_accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1881148ffc8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# training\n",
    "cnn_model.fit(x_train, y_train, batch_size=256, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.6729 - accuracy: 0.8803\n",
      "Test loss: 0.6728541254997253\n",
      "Test accuracy: 0.880299985408783\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "test_scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./twits_classification.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stopwords(str_x):\n",
    "    words = str_x.split(' ')\n",
    "    neutral_words = ['people', 'wikipedia', 'one', 'say', 'page', 'know', 'go', 'back', 'take', 'see', 'look', 'article',\n",
    "                     'edit', 'got', 'thing', 'want', 'make']\n",
    "    new_words = list()\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english') or word not in neutral_words:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "# delete all unnecessary symbols\n",
    "df[\"comment_text\"] = df[\"comment_text\"].map(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
    "# lower all words\n",
    "df[\"comment_text\"] = df[\"comment_text\"].map(lambda x: x.lower())\n",
    "# delete all stopwords\n",
    "df[\"comment_text\"] = df[\"comment_text\"].map(delete_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 9374) (750, 6)\n",
      "(250, 9374) (250, 6)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"comment_text\"].values).toarray()\n",
    "Y = df.iloc[:, 3:].values\n",
    "num_samples = X.shape[0]\n",
    "train_samples = int(0.75*num_samples)\n",
    "indexes = np.arange(num_samples)\n",
    "random.shuffle(indexes)\n",
    "X, Y = X[indexes], Y[indexes]\n",
    "x_train, y_train = X[:train_samples, :], Y[:train_samples]\n",
    "x_test, y_test = X[train_samples:, :], Y[train_samples:]\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 9374, 1)]         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 67,334\n",
      "Trainable params: 67,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "inputs = keras.Input(shape=(9374, 1))\n",
    "x = keras.layers.LSTM(128)(inputs)\n",
    "outputs = keras.layers.Dense(6, activation=\"softmax\")(x)\n",
    "rnn_model = keras.Model(inputs=inputs, outputs=outputs, name=\"rnn_model\")\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "150/150 [==============================] - 895s 6s/step - loss: 0.3826 - accuracy: 0.9300 - val_loss: 0.4677 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "150/150 [==============================] - 1063s 7s/step - loss: 0.3804 - accuracy: 0.9967 - val_loss: 0.4736 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "150/150 [==============================] - 1093s 7s/step - loss: 0.3783 - accuracy: 0.9967 - val_loss: 0.4723 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18817d5f1c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# training\n",
    "rnn_model.fit(x_train, y_train, batch_size=4, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 22s - loss: 0.3257 - accuracy: 0.9960\n",
      "Test loss: 0.325701504945755\n",
      "Test accuracy: 0.9959999918937683\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "test_scores = rnn_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
